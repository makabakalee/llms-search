# Sculptor: Empowering LLMs with Cognitive Agency via Active Context Management

Mo Li $^{1}$ , L.H. Xu $^{2}$ , Qitai Tan $^{1}$ , Ting Cao $^{1}$ *Yunxin Liu $^{1}$ $^{1}$ Tsinghua University   $^{2}$ Independent Researcher

# Abstract

Large Language Models (LLMs) suffer from significant performance degradation when processing long contexts due to proactive interference, where irrelevant information in earlier parts of the context disrupts reasoning and memory recall. While most research focuses on external memory systems to augment LLMs' capabilities, we propose a complementary approach: empowering LLMs with Active Context Management (ACM) tools to actively sculpt their internal working memory. We introduce Sculptor, a framework that equips LLMs with three categories of tools: (1) context fragmentation, (2) summary, hide, and restore, and (3) intelligent search. Our approach enables LLMs to proactively manage their attention and working memory, analogous to how humans selectively focus on relevant information while filtering out distractions. Experimental evaluation on information- sparse benchmarks—PI- LLM (proactive interference) and NeedleBench Multi- Needle Reasoning—demonstrates that Sculptor significantly improves performance even without specific training, leveraging LLMs' inherent tool calling generalization capabilities. By enabling Active Context Management, Sculptor not only mitigates proactive interference but also provides a cognitive foundation for more reliable reasoning across diverse long- context tasks—highlighting that explicit context- control strategies, rather than merely larger token windows, are key to robustness at scale.

# 1 Introduction

Large Language Models (LLMs) have demonstrated remarkable capabilities across diverse tasks, yet they face fundamental challenges when processing long contexts. Prior work shows that simply enlarging the context window leaves models vulnerable to position bias, overload, and interference as sequences show [Liu et al., 2023, Hsieh et al., 2024a]. Recent studies [Wang and Sun, 2025] have empirically demonstrated that LLMs suffer from proactive interference, where earlier information in the context disrupts the processing of subsequent, more relevant information. Moreover, calibrations like Found in the Middle [Hsieh et al., 2024b] reduce—but do not eliminate—positional bias; recent evaluations [Tian et al., 2025] find that performance still degrades significantly when the distance between relevant information pieces increases, as irrelevant information between them interferes with effective information integration. These phenomena mirror human cognitive psychology, where new learning can be impaired by previously acquired information that is no longer relevant to the current task.

The challenge becomes particularly acute in complex, multi- step reasoning tasks where LLMs must maintain focus on multiple critical information pieces while filtering out contextual noise [Li et al., 2025a]. Traditional approaches to address long- context challenges have primarily focused on expanding context windows or developing external memory systems [Li et al., 2025c, Wang and Chen, 2025, Chhikara et al., 2025]. While these solutions increase the amount of information an LLM

![](https://cdn-mineru.openxlab.org.cn/result/2025-08-07/46f62a39-7b15-4fe7-a693-a4d479d8c006/61193b6d4f04ff2aa57805dc5ea02cd7d0b155a89f69057ef9a60f427920a770.jpg)  
Figure 1: Overview of Sculptor framework: LLMs transform from being overwhelmed by cluttered context (left) to successfully solving solving tasks within noisy contexts by actively curating their working memory through context folding and organization (right).

can access, they do not address the fundamental issue of proactive interference—the inability to actively manage and curate the working memory that directly influences reasoning processes.

Consider a human expert working on a complex problem: they naturally employ active memory management strategies, selectively attending to relevant information, summarizing key insights, and temporarily setting aside less important details. They can revisit previously discarded information when needed, but crucially, they do not allow irrelevant details to continuously interfere with their current reasoning process. Current LLMs lack this fundamental cognitive capability. We propose that the solution lies not merely in expanding memory capacity, but in empowering LLMs with the ability to actively manage their internal working memory. Unlike external memory systems that store information outside the model's immediate context, we focus on optimizing the model's working memory—the immediate working space where attention operates and reasoning occurs.

To this end, we introduce Sculptor, a novel framework that treats LLMs as active sculptors of their own context. Just as a sculptor views a block of marble and selectively removes material to reveal the desired form, Sculptor achieves this through a process we call Active Context Management (ACM), as illustrated in Figure 1. We equip LLMs with the Sculptor tool suite that enables them to: (1) Fragment and Organize: Segment long conversations into manageable pieces with unique IDs for easy reference. (2)Summary, Hide, and Restore: Generate focused summaries, dynamically fold irrelevant sections to reduce clutter, and flexibly restore or expand content as needed. (3) Search and Retrieve: Perform both exact and semantic searches to quickly locate relevant information

This approach represents a paradigm shift from passively processing ever- growing contexts to active context curation. Instead of being overwhelmed by increasingly long contexts, LLMs learn to proactively manage their attention and working memory, focusing computational resources on the most relevant information. We view Sculptor as a representative of this emerging direction—complementary to external memory and context extension—providing a necessary step toward reliable long- horizon reasoning. Related work on context compression [Xu et al., 2023, Jiang et al., 2024] further demonstrates that selectively foregrounding key information can simultaneously improve accuracy and reduce cost/latency, reinforcing the need for explicit context control over passive attention alone. Recent work also suggests that in- context learning can be viewed as implicit weight updates [Dherin et al., 2025], implying that allowing models to modify their own context enables a form of “self- evolution” [Zhang et al., 2025]—a step toward agents that can adapt their computational substrate without external intervention.

Our key contributions are as follows:

- We propose Active Context Management (ACM) for LLMs and realize it with Sculptor, a toolkit that enables principled, systematic optimization of internal working memory through active context manipulation.- We conduct preliminary evaluations on two information-sparse benchmarks: PI-LLM for proactive interference and NeedleBench Multi-Needle Reasoning for information retrieval and reasoning, demonstrating promising improvements over baseline approaches.- We discuss ACM limitations, particularly the computational trade-offs from context reshaping, and outline future work including RL-based approaches to enhance tool capabilities.

# 2 Related Work

Long- Context Processing, Memory, and Evaluation Effectively processing long contexts remains a critical challenge for LLMs. Early efforts focused on expanding context windows through architectural improvements [Beltagy et al., 2020, Su et al., 2023, Chen et al., 2023]. Subsequently, a substantial body of work sought to further optimize performance by augmenting LLMs with external memory systems, employing comprehensive memory architectures and multi- agent frameworks to overcome context limitations [Li et al., 2025c, Yang et al., 2024, Li et al., 2025b. Wang and Chen, 2025, Ohikara et al., 2025, Yu et al., 2025f. The push for longer and more complex context processing led to the development of specialized evaluation benchmarks, such as NIAH [Kamradt, 2023],NeedleBench [Li et al., 2025a], RULER [Hsieh et al., 2024a],LongBench- v2 [Bai et al., 2025], MRCR [Vodrahalli et al., 2024], and PI- LLM [Wang and Sun, 2025]. These benchmarks were instrumental in revealing that despite architectural and memory enhancements, modern LLMs still perform poorly on information- sparse tasks. Among these, work such as PI- LLM further identified a deeper reason for this phenomenon: proactive interference, where earlier information in the context disrupts the processing of later, more relevant content [Wang and Sun, 2025]. These documented failures on information- sparse tasks, coupled with the diagnosis of proactive interference, provide a strong motivation for our approach of active context management. Unlike external memory solutions that focus on storage and retrieval, or traditional attention that uniformly processes all tokens, our method provides the model with explicit tools to selectively retain, compress, or ignore information directly within its working memory, thereby mitigating interference without altering the underlying architecture.

Tool- Augmented Language Models The integration of external tools to augment LLM capabilities is a burgeoning field of research, designed to overcome inherent model limitations such as knowledge cutoffs, hallucination, and weak mathematical reasoning. Pioneering work in this area has largely followed two paradigms. On one hand, models like Toolformer [Schick et al., 2023] demonstrate that LLMs can be fine- tuned to learn when and how to call external APIs, seamlessly incorporating their outputs into the generation process. On the other hand, prompting- based frameworks like ReAct [Yao et al., 2023] show that LLMs can synergize chain- of- thought reasoning with tool use in a zero- shot manner, interleaving thought, action, and observation steps to solve complex tasks. Subsequent research has focused on improving the reliability and scope of tool use, with work like Gorilla [Patil et al., 2023] developing models specialized for accurate API invocation, and frameworks like ART [Paranjape et al., 2023] creating programmatic pipelines for tool- augmented multi- step reasoning. However, a common thread in this existing literature is the focus on using tools to interact with the external world- accessing calculators, search engines, or code interpreters. Sculptor diverges from this trend by proposing a novel class of tools for internal context management. Instead of augmenting the LLM with external knowledge, we empower it with cognitive tools to actively curate its own working memory. This positions our work as complementary to existing tool- use research. Our approach directly targets cognitive bottlenecks like proactive interference, rather than solely addressing knowledge or computational limitations.

# 3 Methodology

# 3.1 The Sculptor Framework for Active Context Management

3.1 The Sculptor Framework for Active Context ManagementSculptor introduces a paradigm shift in how LLMs handle their working memory. Instead of passively accepting all information in their context window, we empower models to actively manage their attention through a suite of context manipulation tools. Our framework operates on the principle that intelligent information curation is as important as information capacity.

# 3.2 The Sculptor Tool Suite

We equip LLMs with eight fundamental tools organized into four functional categories.

(1) Context Fragmentation is handled by fragment_context, which segments long conversations into manageable fragments using start and end markers, with each fragment receiving a unique 6-character ID for easy reference.

(2) Summary, Hide, and Restore involves five complementary tools for dynamic content management. summary_fragment generates focused AI-powered summaries of specific fragments using configurable LLM models, while revert_summary restores summarized content back to its original form, ensuring no information is permanently lost. fold_fragment hides fragment content while preserving its existence, displaying only a folded marker with character count to dramatically reduce visual clutter. expand_fragment reveals previously folded content when it becomes relevant again, enabling dynamic focus management throughout conversations. restore_context provides a complete reset mechanism that clears all fragment states and returns the conversation to its original form.

(3) Intelligent Search and Retrieval is accomplished through search_context, a unified interface supporting both exact matching and semantic search modes across user messages, assistant responses, or all content, with configurable similarity thresholds using OpenAI embeddings. get_search_detail retrieves extended context around search results, with the model specifying the desired surrounding character count. By appending search results to the end of conversation history, this approach mitigates the "lost in the middle" problem [Liu et al., 2023] where models struggle to locate information buried within long contexts.

# 3.3 Teaching LLMs to Use Sculptor Tools

We explore two approaches for enabling LLMs to effectively utilize the Sculptor tools. (1) Zero- shot tool calling leverages the inherent tool- calling capabilities of state- of- the- art models like Claude- 4- Sonnet and GPT- 4.1, which demonstrate strong zero- shot generalization abilities for function calling. These models can understand and execute our Sculptor tools without any specific training, relying on their pre- trained understanding of tool usage patterns and natural language descriptions of tool schema. To encourage consistent tool engagement, we set tool_choice="required" for the first round of multi- turn conversations.

(2) Multi-turn RL training involves reinforcement learning where models learn optimal tool usage strategies through iterative feedback and reward signals. This approach aims to develop more sophisticated tool usage patterns and better timing decisions for when to apply different ACM operations. While this training approach shows promising potential for further performance improvements, it is currently a work in progress and results are not yet available for evaluation.

# 4 Experiments

4 ExperimentsWe explore the effectiveness of Sculptor through direct tool calling without specific training. Currently, even with no targeted training, through appropriate prompt engineering and leveraging LLMs' inherent tool calling generalization capabilities, we achieve improved performance on information- sparse tasks. Results from multi- turn RL training approaches are ongoing work and will be updated in future versions.

Table 1: PI-LLM task results for selected models and their ACM tools variants.  

<table><tr><td rowspan="3">Model</td><td colspan="8">Update Count</td><td rowspan="2">Overall</td></tr><tr><td>2</td><td>4</td><td>8</td><td>16</td><td>32</td><td>64</td><td>128</td><td>256</td></tr><tr><td>0.5K</td><td>1K</td><td>2K</td><td>4K</td><td>8K</td><td>16K</td><td>32K</td><td>64K</td><td>Average</td></tr><tr><td>Claude-4-Sonnet</td><td>99.87</td><td>99.13</td><td>95.65</td><td>92.17</td><td>84.78</td><td>81.74</td><td>65.22</td><td>69.57</td><td>86.02</td></tr><tr><td>Claude-4-Sonnet (w/ ACM Tools.)</td><td>79.57</td><td>90.43</td><td>91.74</td><td>98.26</td><td>92.17</td><td>91.74</td><td>87.39</td><td>77.83</td><td>88.64</td></tr><tr><td>GPT-4.1</td><td>100.00</td><td>96.96</td><td>91.39</td><td>79.57</td><td>67.83</td><td>63.04</td><td>63.91</td><td>50.45</td><td>76.63</td></tr><tr><td>GPT-4.1 (w/ ACM Tools.)</td><td>98.26</td><td>92.17</td><td>89.13</td><td>93.04</td><td>83.91</td><td>76.09</td><td>64.35</td><td>60.43</td><td>82.17</td></tr><tr><td>DeepSeek-V3-0324</td><td>100.00</td><td>95.22</td><td>85.65</td><td>70.00</td><td>63.91</td><td>33.04</td><td>32.17</td><td>21.74</td><td>62.72</td></tr><tr><td>DeepSeek-V3-0324 (w/ ACM Tools.)</td><td>53.48</td><td>73.91</td><td>90.00</td><td>79.13</td><td>37.39</td><td>53.04</td><td>55.65</td><td>11.74</td><td>56.79</td></tr></table>

Table 2: Multi-Needle Reasoning Task Results of NeedleBench-128K.  

<table><tr><td>Model</td><td>2-Needle</td><td>3-Needle</td><td>4-Needle</td><td>5-Needle</td><td>Overall</td></tr><tr><td>Claude-4-Sonnet</td><td>96.0</td><td>82.0</td><td>54.0</td><td>36.0</td><td>67.0</td></tr><tr><td>Claude-4-Sonnet (w/ ACM Tools.)</td><td>100.0</td><td>98.0</td><td>88.0</td><td>90.0</td><td>94.0</td></tr><tr><td>GPT-4.1</td><td>90.0</td><td>64.0</td><td>30.0</td><td>8.0</td><td>48.0</td></tr><tr><td>GPT-4.1 (w/ ACM Tools.)</td><td>96.0</td><td>84.0</td><td>60.0</td><td>44.0</td><td>71.0</td></tr><tr><td>DeepSeek-V3-0324</td><td>88.0</td><td>68.0</td><td>28.0</td><td>16.0</td><td>50.0</td></tr><tr><td>DeepSeek-V3-0324 (w/ ACM Tools.)</td><td>92.0</td><td>58.0</td><td>50.0</td><td>32.0</td><td>58.0</td></tr></table>

# 4.1Evaluated Models and Benchmarks

We evaluate the effectiveness of Sculptor by comparing LLMs with and without the Sculptor tool suite across challenging benchmarks. Our experiments focus on Claude- 4- Sonnet [Anthropic, 2025], GPT- 4.1 [OpenAI, 2025], and DeepSeek- V3 [DeepSeek- AI et al., 2024] as representative state- ofthe- art models, testing both baseline configurations and Sculptor- enhanced versions.

We conduct preliminary evaluations on benchmarks that test proactive interference and long- context capabilities. (1) PI- LLM [Wang and Sun, 2025] tests proactive interference by continuously updating key- value pairs, measuring how well models can forget outdated information and focus on current mappings. We set update counts from 2 to 256 and average the results, with 46 update keys following the paper's recommended settings, repeating each test 5 times. (2) NeedleBench [Li et al., 2025a] evaluates information retrieval and reasoning in varying information densities by requiring models to find and connect multiple pieces of information scattered throughout long documents. We select the Multi- Needle Reasoning task with fixed depth of 40, testing across context lengths of 1k, 2k, 16k, 64k, and 128k tokens, averaging results over 10 runs per dataset.

# 4.2Evaluation Results

# 4.2.1Main Results

4.2 Evaluation Results4.2.1 Main ResultsTables 1 and 2 present the comprehensive evaluation results across PI- LLM and NeedleBench benchmarks. The results demonstrate overall improvements when models are equipped with Sculptor tools, particularly on tasks suffering from proactive interference or requiring multi- needle reasoning.

# 4.2.2 Performance Analysis by Benchmark

4.2.2 Performance Analysis by BenchmarkPI- LLM Results: Sculptor tools provide improvements on the PI- LLM benchmark for most models. Claude- 4- Sonnet and GPT- 4.1 achieve gains of 2.62 and 5.54 points respectively, while DeepSeek- V3 shows a decrease of 5.93 points, indicating varying generalization capabilities to unseen tools across models. Tool usage occasionally leads to score degradation at specific update counts - Claude- 4- Sonnet drops from 99.87 to 79.57 at update count 2, and DeepSeek- V3 shows an even larger drop from 100.00 to 53.48, as models sometimes over- fold useful information. Despite these variations, two out of three models show overall improvements, demonstrating successful transfer of tool- calling capabilities to long- context tasks. Models primarily leverage fragment, context and fold_fragment to "sculpt away" proactive interference.

![](https://cdn-mineru.openxlab.org.cn/result/2025-08-07/46f62a39-7b15-4fe7-a693-a4d479d8c006/66f81d8bfd9ebc6b1059e5c3e25a9caa465be2f17ec4eea302c9ad0b450a2a23.jpg)  
Figure 2: NeedleBench Multi-Needle Reasoning performance of Claude-4-Sonnet across different context lengths. The model with Sculptor tools (blue) consistently outperforms the vanilla model (purple), with performance gaps widening as needle count increases.

![](https://cdn-mineru.openxlab.org.cn/result/2025-08-07/46f62a39-7b15-4fe7-a693-a4d479d8c006/9cf68b44f457d1a281a251d7b25de6e178f84023bd1ce8b7a606679c71754ba9.jpg)  
Figure 3: Average performance comparison of Claude-4-Sonnet across all needle counts. Sculptor tools provide substantial improvements, particularly at longer context lengths where the vanilla model struggles significantly.

NeedleBench Results: On multi- needle reasoning tasks, all Sculptor- enhanced models achieve improvements across different needle counts, as shown in Figures 2 and 3. Claude- 4- Sonnet, GPT- 4.1, and DeepSeek- V3 achieve gains of 27.0, 23.0, and 8.0 points respectively, with Claude- 4- Sonnet reaching 90% accuracy even on 5- needle tasks. Unlike PI- LLM where models prefer fragment_context and fold_fragment, multi- needle reasoning tasks predominantly trigger search_context usage for rapid needle localization, explaining the consistent improvements across all models.

# 5 Limitations and Future Work

Although Sculptor achieves significant improvements on multiple benchmarks, it introduces a computational trade- off: active context management reshapes the input context, invalidating traditional prefix- based KV cache mechanisms and potentially increasing computational costs. We anticipate future infrastructure optimizations, including adaptive caching strategies, will mitigate this issue.

Additionally, current LLMs rely on generalization from tool- use training in other domains to operate ACM tools, which does not guarantee stable or correct usage. Future work includes leveraging reinforcement learning to train LLMs to effectively and selectively use active context management tools across diverse benchmarks, developing advanced tool scheduling algorithms to minimize cache invalidation, and exploring architectural changes to enable partial cache reuse.

# Acknowledgments

AcknowledgmentsWe sincerely thank Chupei Wang and Jiaqiu Vince Sun for valuable discussions on proactive interference, and Yongting Zhang for discussions on tool design.

# References

ReferencesAnthropic. System Card: Claude Opus 4 & Claude Sonnet 4. https://www- cdn.anthropic.com/4263b940cabb546aa0e3283f35b686f4f3b2ff47. pdf, May 2025. Accessed: 2025- 08- 05. Yushi Bai, Shangqing Tu, Jiajie Zhang, Hao Peng, Xiaozhi Wang, Xin Lv, Shulin Cao, Jiazheng Xu, Lei Hou, Yuxiao Dong, Jie Tang, and Juanzi Li. Longbench v2: Towards deeper understanding and reasoning on realistic long- context multitasks, 2025. URL https://arxiv.org/abs/2412.15204. Iz Beltagy, Matthew E. Peters, and Arman Cohan. Longformer: The long- document transformer, 2020. URL https://arxiv.org/abs/2004.05150. Shouyuan Chen, Sherman Wong, Liangjian Chen, and Yuandong Tian. Extending context window of large language models via positional interpolation, 2023. URL https://arxiv.org/abs/2306.15595. Prateek Chhikara, Dev Khant, Saket Aryan, Taranjeet Singh, and Deshraj Yadav. Mem0: Building production- ready ai agents with scalable long- term memory. arXiv preprint arXiv:2504.19413, 2025. DeepSeek- AI, Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, et al. DeepSeek- V3 Technical Report. https://arxiv.org/abs/2412.19437, December 2024. Benoit Dherin, Michael Munn, Hanna Mazzawi, Michael Wunder, and Javier Gonzalvo. Learning without training: The implicit dynamics of in- context learning, 2025. URL https://arxiv.org/abs/2507.16003. Cheng- Ping Hsieh, Simeng Sun, Samuel Kriman, Shantanu Acharya, Dima Rekesh, Fei Jia, Yang Zhang, and Boris Ginsburg. Ruler: What's the real context size of your long- context language models?. 2024a. URL https://arxiv.org/abs/2404.06654. Cheng- Yu Hsieh, Yung- Sung Chuang, Chun- Liang Li, Zifeng Wang, Long T. Le, Abhishek Kumar, James Glass, Alexander Ratner, Chen- Yu Lee, Ranjay Krishna, and Tomas Pfister. Found in the middle: Calibrating positional attention bias improves long context utilization, 2024b. URL https://arxiv.org/abs/2406.16008. Huiqiang Jiang, Qianhui Wu, Xufang Luo, Dongsheng Li, Chin- Yew Lin, Yuqing Yang, and Lili Qiu. Longllmlingua: Accelerating and enhancing llms in long context scenarios via prompt compression, 2024. URL https://arxiv.org/abs/2310.06839. Greg Kamradt. LLMs Need Needle In A Haystack Test- Pressure Testing LLMs. https://github.com/gkamradt/LLMTest_NeedleInAHaystack, 2023.

Mo Li, Songyang Zhang, Taolin Zhang, Haodong Duan, Yunxin Liu, and Kai Chen. Needlebench: Can llms do retrieval and reasoning in information- dense context?, 2025a. URL https://arxiv.org/abs/2407.11963. Zhiyu Li, Shichao Song, Hanyu Wang, Simin Niu, Ding Chen, Jiawei Yang, Chenyang Xi, Huayi Lai, Jihao Zhao, Yezhaohui Wang, et al. Memos: An operating system for memory- augmented generation (mag) in large language models. arXiv preprint arXiv:2505.22101, 2025b. URL https://arxiv.org/abs/2505.22101. Zhiyu Li, Shichao Song, Chenyang Xi, Hanyu Wang, Chen Tang, Simin Niu, Ding Chen, Jiawei Yang, Chunyu Li, Qingchen Yu, Jihao Zhao, Yezhaohui Wang, Peng Liu, Zehao Lin, Pengyuan Wang, Jiahao Hue, Tianyi Chen, Kai Chen, Kehang Li, Zhen Tao, Junpeng Ren, Huayi Lai, Hao Wu, Bo Tang, Zhenren Wang, Zhaoxin Fan, Ningyu Zhang, Linfeng Zhang, Junchi Yan, Mingchuan Yang, Tong Xu, Wei Xu, Huajun Chen, Haofeng Wang, Hongkang Yang, Wentao Zhang, Zhi- Qin John Xu, Siheng Chen, and Feiyu Xiong. Memos: A memory os for ai system. arXiv preprint arXiv:2507.03724, 2025c. URL https://arxiv.org/abs/2507.03724. Nelson F. Liu, Kevin Lin, John Hewitt, Ashwin Paranjape, Michele Bevilacqua, Fabio Petroni, and Percy Liang. Lost in the middle: How language models use long contexts, 2023. URL https://arxiv.org/abs/2307.03172. OpenAI. Introducing GPT- 4.1 in the API. https://openai.com/index/gpt- 4- 1/, April 2025. Accessed: 2025- 08- 05. Bhargavi Paranjape, Scott Lundberg, Sameer Singh, Hannaneh Hajishirzi, Luke Zettlemoyer, and Marco Tulio Ribeiro. Art: Automatic multi- step reasoning and tool- use for large language models, 2023. URL https://arxiv.org/abs/2303.08014. Shishir G. Patil, Tianjun Zhang, Xin Wang, and Joseph E. Gonzalez. Gorilla: Large language model connected with massive apis, 2023. URL https://arxiv.org/abs/2305.15334. Timo Schick, Jane Dwivedi- Yu, Roberto Dessi, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to use tools, 2023. URL https://arxiv.org/abs/2302.04761. Jianlin Su, Yu Lu, Shengfeng Pan, Ahmed Murtadha, Bo Wen, and Yunfeng Liu. Roformer: Enhanced transformer with rotary position embedding, 2023. URL https://arxiv.org/abs/2104.09864. Runchu Tian, Yanghao Li, Yuepeng Fu, Siyang Deng, Qinyu Luo, Cheng Qian, Shuo Wang, Xin Cong, Zhong Zhang, Yesai Wu, Yankai Lin, Huadong Wang, and Xiaojiang Liu. Distance between relevant information pieces causes bias in long- context llms, 2025. URL https://arxiv.org/abs/2410.14641. Kiran Vodahalli, Santiago Ontanon, Nilesh Tripuraneni, Kelvin Xu, Sanil Jain, Rakesh Shivanna, Jeffrey Hut, Nishanth Dikkala, Mehran Kazemi, Rohare Fatemi, Rohan Anil, Ethan Dyer, Siamak Shakeri, Roopali Vij, Harsh Mehta, Vinay Ramasesh, Quoc Le, Ed Chi, Yifeng Lu, Orhan Firat, Angelik, Lazaridou, Jean- Baptiste Lespiau, Nithya Attaluri, and Kate Olszewska. Michelangelo: Long context evaluations beyond haystacks via latent structure queries, 2024. URL https://arxiv.org/abs/2409.12640. Chupei Wang and Jiaqiu Vince Sun. Unable to forget: Proactive interference reveals working memory limits in llms beyond context length, 2025. URL https://arxiv.org/abs/2506.08184. Yu Wang and Xi Chen. Mirix: Multi- agent memory system for llm- based agents, 2025. URL https://arxiv.org/abs/2507.07957. Fangyuan Xu, Weijia Shi, and Eunsol Choi. Recomp: Improving retrieval- augmented llms with compression and selective augmentation, 2023. URL https://arxiv.org/abs/2310.04408. Hongkang Yang, Lin Zehao, Wang Wenjin, Hao Wu, Li Zhiyu, Bo Tang, Wei Wenqiang, Jinbo Wang, Tang Zeyun, Shichao Song, Chenyang Xi, Yu Yu, Chen Kai,

Feiyu Xiong, Linpeng Tang, and E Weinan. Memory $^{3}$ : Language modeling with explicit memory. Journal of Machine Learning, 3(3):300- 346, 2024. ISSN 2790- 2048. doi: https://doi.org/10.4208/jml.240708. URL https://global- sci.com/article/91443/memory3- language- modeling- with- explicit- memory.Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language models, 2023. URL https://arxiv.org/abs/2210.03629. Hongli Yu, Tinghong Chen, Jiangtao Feng, Jiangjie Chen, Weinan Dai, Qiying Yu, Ya- Qin Zhang, Wei- Ying Ma, Jingjing Liu, Mingxuan Wang, and Hao Zhou. Memagent: Reshaping long- context ltm with multi- conv rl- based memory agent, 2025. URL https://arxiv.org/abs/2507.02259. Jenny Zhang, Shengran Hu, Cong Lu, Robert Lange, and Jeff Clune. Darwin godel machine: Open- ended evolution of self- improving agents, 2025. URL https://arxiv.org/abs/2505.22954.
